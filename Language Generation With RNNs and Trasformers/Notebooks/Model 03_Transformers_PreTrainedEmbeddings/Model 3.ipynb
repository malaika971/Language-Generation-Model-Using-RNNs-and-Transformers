{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcb75c2-605e-48f2-99a8-eed08d849fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 18:00:26.677672: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d064e28-f23a-4a1c-babb-474c8a325330",
   "metadata": {},
   "source": [
    "### Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0793fd84-e4ba-45e8-9a09-df74376d9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/aneebaaslam/Desktop/merged_text.txt', 'r') as file:\n",
    "    corpus = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4a910-d4b7-4a55-a57e-a35cd88ebad6",
   "metadata": {},
   "source": [
    "### Tokenization and lowecase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7272676-fd40-4257-b859-26eb03aa9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
    "tokenized_corpus = [[word.lower() for word in sentence] for sentence in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b298153-80f9-4692-9633-bde93ac9887b",
   "metadata": {},
   "source": [
    "### Loading the embedding file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c503060-82ee-4c38-a57c-75ef2e9f7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(embedding_file):\n",
    "    embeddings_index = {}\n",
    "    with open(embedding_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embedding_file = '/Users/aneebaaslam/Desktop/glove.6B.50d.txt'  \n",
    "embeddings_index = load_glove_embeddings(embedding_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671cf99-ea9b-4517-88b4-4d385fb1f125",
   "metadata": {},
   "source": [
    "### Initializing Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbab814-4a3c-44fb-91d2-ca64b063c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)  # Creating sequences\n",
    "sequences = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a2409-7348-4749-a8e7-b49f089c4c81",
   "metadata": {},
   "source": [
    "### Padding Sequences and Vocab Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c6e974a-1ab1-46f7-ab18-8e34317532f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(seq) for seq in sequences)  # Longest sentence\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99daaf1-4d85-4dca-9fa6-f7b323cd6803",
   "metadata": {},
   "source": [
    "### Embedding Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c8112a-5ce0-4a44-982d-3559c0fbb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.stack(list(embeddings_index.values()))\n",
    "emb_mean = np.mean(all_embeddings)\n",
    "emb_std = np.std(all_embeddings)\n",
    "\n",
    "\n",
    "embedding_dim = 50  \n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector  # Use the GloVe vector\n",
    "    else:\n",
    "        # Generate a random vector where the mean and std are aligned with GloVe's distribution\n",
    "        embedding_matrix[idx] = np.random.normal(loc=emb_mean, scale=emb_std, size=(embedding_dim,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdad0e2-14ec-48db-b941-44a07901c41b",
   "metadata": {},
   "source": [
    "### Splitting corpus into training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "375fe4e4-d31d-47ec-989c-9210a501d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_sequences[:, :-1]\n",
    "y = padded_sequences[:, 1:]\n",
    "\n",
    "# Splitting the data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33254c-86d4-433c-82d9-5bac759e448a",
   "metadata": {},
   "source": [
    "### Building Transformater Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d031c03-de11-4ed5-9230-1061dc189dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule\n",
    "initial_learning_rate = 0.005\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.85,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Transformer model parameters\n",
    "d_model = 50\n",
    "num_heads = 8\n",
    "dff = 128\n",
    "dropout_rate = 0.1\n",
    "num_layers = 4\n",
    "vocab_size = 2236 \n",
    "max_sequence_length = 1362 \n",
    "\n",
    "# Input layer for the sequences\n",
    "input_seq = Input(shape=(max_sequence_length,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=d_model,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False\n",
    ")(input_seq)\n",
    "\n",
    "# Encoder layers\n",
    "x = embedding_layer\n",
    "for i in range(num_layers):\n",
    "    attn_output = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model\n",
    "    )(x, x)\n",
    "\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    attn_output = LayerNormalization()(x + attn_output)\n",
    "\n",
    "    ffn_output = Dense(dff, activation='relu')(attn_output)\n",
    "    ffn_output = Dense(d_model)(ffn_output)\n",
    "\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    x = LayerNormalization()(attn_output + ffn_output)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "model = Model(inputs=input_seq, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cddc43-6ad6-4067-adeb-ea83f95ab67f",
   "metadata": {},
   "source": [
    "### Model Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe4d4e94-3ff4-48ae-ad1e-4d8cd2362ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">111,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">81,250</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">81,250</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">81,250</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">81,250</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,036</span> │ layer_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2236</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │    \u001b[38;5;34m111,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │     \u001b[38;5;34m81,250\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m6,528\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m6,450\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │     \u001b[38;5;34m81,250\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m6,528\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m6,450\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │     \u001b[38;5;34m81,250\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m6,528\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m6,450\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │     \u001b[38;5;34m81,250\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m6,528\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m6,450\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │        \u001b[38;5;34m100\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m,      │    \u001b[38;5;34m114,036\u001b[0m │ layer_normalizat… │\n",
       "│                     │ \u001b[38;5;34m2236\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,548</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m603,548\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491,748</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m491,748\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,800</span> (436.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m111,800\u001b[0m (436.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a1b48-c3cf-4dd2-b8c1-eba4248c5fdb",
   "metadata": {},
   "source": [
    "### Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6c19d5d-2097-4b78-9873-75137e7d894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 37s/step - accuracy: 0.7283 - loss: 7.3319 - val_accuracy: 0.8781 - val_loss: 6.0498\n",
      "Epoch 2/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 28s/step - accuracy: 0.9342 - loss: 5.8127 - val_accuracy: 0.8781 - val_loss: 4.8972\n",
      "Epoch 3/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 32s/step - accuracy: 0.9441 - loss: 4.5851 - val_accuracy: 0.8781 - val_loss: 3.6222\n",
      "Epoch 4/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 29s/step - accuracy: 0.9382 - loss: 3.2679 - val_accuracy: 0.8781 - val_loss: 2.3517\n",
      "Epoch 5/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 29s/step - accuracy: 0.9287 - loss: 1.9947 - val_accuracy: 0.8781 - val_loss: 1.4483\n",
      "Epoch 6/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 35s/step - accuracy: 0.9358 - loss: 1.0242 - val_accuracy: 0.8781 - val_loss: 1.2023\n",
      "Epoch 7/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 30s/step - accuracy: 0.9370 - loss: 0.6934 - val_accuracy: 0.8781 - val_loss: 1.2611\n",
      "Epoch 8/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 34s/step - accuracy: 0.9376 - loss: 0.6642 - val_accuracy: 0.8781 - val_loss: 1.3491\n",
      "Epoch 9/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 33s/step - accuracy: 0.9299 - loss: 0.7731 - val_accuracy: 0.8781 - val_loss: 1.4015\n",
      "Epoch 10/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 37s/step - accuracy: 0.9370 - loss: 0.7162 - val_accuracy: 0.8781 - val_loss: 1.3964\n",
      "Epoch 11/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 32s/step - accuracy: 0.9374 - loss: 0.6973 - val_accuracy: 0.8781 - val_loss: 1.2798\n",
      "Epoch 12/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 28s/step - accuracy: 0.9331 - loss: 0.6943 - val_accuracy: 0.8781 - val_loss: 1.1680\n",
      "Epoch 13/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 32s/step - accuracy: 0.9385 - loss: 0.6389 - val_accuracy: 0.8781 - val_loss: 1.2012\n",
      "Epoch 14/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 33s/step - accuracy: 0.9352 - loss: 0.6557 - val_accuracy: 0.8781 - val_loss: 1.2372\n",
      "Epoch 15/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 30s/step - accuracy: 0.9370 - loss: 0.6408 - val_accuracy: 0.8781 - val_loss: 1.2247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x146c1c8f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=33, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01424746-ce84-404c-a94c-f9d2572dfa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Function to generate predictions for a list of sequences\n",
    "\n",
    "def generate_predictions(model, tokenizer, sequences, max_sequence_length):\n",
    "    predictions = []  # List to store predictions\n",
    "    for seq in sequences:\n",
    "\n",
    "        # Preparing the input sequence, ensuring it's the correct shape for the model\n",
    "        input_seq = seq[:max_sequence_length].reshape(1, -1)  \n",
    "\n",
    "        pred_probs = model.predict(input_seq, verbose=0)  # Predicting probabilities for the next word\n",
    "\n",
    "        # Mapping predicted indices to words using the tokenizer's index-to-word mapping\n",
    "        pred_words = [tokenizer.index_word.get(idx, '') for idx in pred_probs.argmax(axis=-1)[0]]\n",
    "        predictions.append(pred_words)  # Appending the predicted words to the list\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bbb664b-e2e8-4b5c-8e45-334b938823be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Function to generate actual words from sequences\n",
    "\n",
    "def generate_actuals(sequences, tokenizer):\n",
    "    actuals = []  # List to store actual sequences in word form\n",
    "    for seq in sequences:\n",
    "        # Converting sequence indices to words\n",
    "        words = [tokenizer.index_word.get(idx, '') for idx in seq]\n",
    "        actuals.append(words)  # Append the actual words to the list\n",
    "    return actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c68d331f-1d9d-48b8-a9fa-0b1eec0cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating  predicted sequences for evaluation\n",
    "predicted_sequences = generate_predictions(model, tokenizer, x_val, max_sequence_length)\n",
    "\n",
    "\n",
    "# Generating actual sequences from the ground truth\n",
    "actual_sequences = generate_actuals(y_val, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "945814e2-d597-4e8e-8583-500b12785fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Scores:\n",
      "BLEU-1: 0.8781\n",
      "BLEU-2: 0.8781\n",
      "BLEU-3: 0.8792\n",
      "BLEU-4: 0.8780\n",
      "\n",
      " ROUGE Scores:\n",
      "ROUGE-1 (F1): 0.0000\n",
      "ROUGE-2 (F1): 0.0000\n",
      "ROUGE-L (F1): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Computing BLEU scores for the predicted and actual sequences\n",
    "smooth_fn = SmoothingFunction().method1  # Smoothing function for BLEU scores\n",
    "\n",
    "# Computing BLEU score for each sentence pair\n",
    "bleu_scores = [sentence_bleu([actual], pred, smoothing_function=smooth_fn)\n",
    "               for actual, pred in zip(actual_sequences, predicted_sequences)]\n",
    "# Compute corpus-level BLEU scores with different n-gram weights\n",
    "bleu_1 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(1.0, 0, 0, 0))\n",
    "bleu_2 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.5, 0.5, 0, 0))\n",
    "bleu_3 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.33, 0.33, 0.33, 0))\n",
    "bleu_4 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "# Printing BLEU scores\n",
    "print(\"BLEU Scores:\")\n",
    "print(f\"BLEU-1: {bleu_1:.4f}\")\n",
    "print(f\"BLEU-2: {bleu_2:.4f}\")\n",
    "print(f\"BLEU-3: {bleu_3:.4f}\")\n",
    "print(f\"BLEU-4: {bleu_4:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Computing ROUGE scores using a scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "# Initialize cumulative ROUGE scores with offsets for clarity\n",
    "rouge_1, rouge_2, rouge_l = 0, 0, 0\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over actual and predicted sequences\n",
    "for actual, pred in zip(actual_sequences, predicted_sequences):\n",
    "    # Converting sequences to strings for scoring\n",
    "    actual_str = ' '.join(actual)\n",
    "    pred_str = ' '.join(pred)\n",
    "    # Computing ROUGE scores for the pair\n",
    "    scores = scorer.score(actual_str, pred_str)\n",
    "    rouge_1 += scores['rouge1'].fmeasure  # Accumulate ROUGE-1 F1 scores\n",
    "    rouge_2 += scores['rouge2'].fmeasure  # Accumulate ROUGE-2 F1 scores\n",
    "    rouge_l += scores['rougeL'].fmeasure  # Accumulate ROUGE-L F1 scores\n",
    "\n",
    "\n",
    "\n",
    "# Averaging ROUGE scores over all sequences\n",
    "n = len(actual_sequences)\n",
    "print(\"\\n ROUGE Scores:\")\n",
    "print(f\"ROUGE-1 (F1): {rouge_1 / n:.4f}\")\n",
    "print(f\"ROUGE-2 (F1): {rouge_2 / n:.4f}\")\n",
    "print(f\"ROUGE-L (F1): {rouge_l / n:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f242cda-1de8-4214-ad9c-67007b571d81",
   "metadata": {},
   "source": [
    "#  4×  MODEL 3 CHECK POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15a00f-1606-46e7-88aa-b10537da1f62",
   "metadata": {},
   "source": [
    "#### Checkpoint 1: After Training glove.6B.50d Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc12b1a3-3718-4790-afd7-f7db0f09ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GloVe_model_checkpoint.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d5ef1-66aa-4ce3-ab34-1d6719c0731d",
   "metadata": {},
   "source": [
    "#### Checkpoint 2: After Initializing the Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6198793-d906-4dc4-840f-f426e29e7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding_matrix_checkpoint.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a88a6-e91f-4ed4-a91e-75529eccc4b4",
   "metadata": {},
   "source": [
    "#### Checkpoint 3: After Each Training Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e27aea34-8d63-4a5c-abf3-66c263f93f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 30s/step - accuracy: 0.9447 - loss: 0.5628 - val_accuracy: 0.8781 - val_loss: 1.1953\n",
      "Epoch 2/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 30s/step - accuracy: 0.9306 - loss: 0.6928 - val_accuracy: 0.8781 - val_loss: 1.1784\n",
      "Epoch 3/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 29s/step - accuracy: 0.9372 - loss: 0.6372 - val_accuracy: 0.8781 - val_loss: 1.2032\n",
      "Epoch 4/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 31s/step - accuracy: 0.9383 - loss: 0.6225 - val_accuracy: 0.8781 - val_loss: 1.2311\n",
      "Epoch 5/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 26s/step - accuracy: 0.9345 - loss: 0.6578 - val_accuracy: 0.8781 - val_loss: 1.2326\n",
      "Epoch 6/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 31s/step - accuracy: 0.9324 - loss: 0.6805 - val_accuracy: 0.8781 - val_loss: 1.2196\n",
      "Epoch 7/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 29s/step - accuracy: 0.9300 - loss: 0.6978 - val_accuracy: 0.8781 - val_loss: 1.2059\n",
      "Epoch 8/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 37s/step - accuracy: 0.9292 - loss: 0.7014 - val_accuracy: 0.8781 - val_loss: 1.2085\n",
      "Epoch 9/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 36s/step - accuracy: 0.9330 - loss: 0.6688 - val_accuracy: 0.8781 - val_loss: 1.2186\n",
      "Epoch 10/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 30s/step - accuracy: 0.9384 - loss: 0.6225 - val_accuracy: 0.8781 - val_loss: 1.2246\n",
      "Epoch 11/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 27s/step - accuracy: 0.9421 - loss: 0.5856 - val_accuracy: 0.8781 - val_loss: 1.2206\n",
      "Epoch 12/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 29s/step - accuracy: 0.9387 - loss: 0.6155 - val_accuracy: 0.8781 - val_loss: 1.2089\n",
      "Epoch 13/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 28s/step - accuracy: 0.9394 - loss: 0.6107 - val_accuracy: 0.8781 - val_loss: 1.2078\n",
      "Epoch 14/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 29s/step - accuracy: 0.9362 - loss: 0.6402 - val_accuracy: 0.8781 - val_loss: 1.2089\n",
      "Epoch 15/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 27s/step - accuracy: 0.9348 - loss: 0.6491 - val_accuracy: 0.8781 - val_loss: 1.2171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14c49a600>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_checkpoint_epoch_{epoch:02d}.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False\n",
    ")\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=15, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b92ef78-94e6-41da-b0d5-fe94a89b2fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model_checkpoint_epoch_15.weights.h5' target='_blank'>model_checkpoint_epoch_15.weights.h5</a><br>"
      ],
      "text/plain": [
       "/Users/aneebaaslam/Desktop/model_checkpoint_epoch_15.weights.h5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "epoch = 15\n",
    "filename = f'model_checkpoint_epoch_{epoch:02d}.weights.h5'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    # Create a download link\n",
    "    display(FileLink(filename))\n",
    "else:\n",
    "    print(f\"Error: File '{filename}' not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75850de-36f2-468f-8e5c-94ee136354b5",
   "metadata": {},
   "source": [
    "#### Checkpoint 4: Best Performance Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b13ef2a-0454-4f3f-9cc6-3e20743cb382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23s/step - accuracy: 0.9445 - loss: 0.5667 \n",
      "Epoch 1: val_loss improved from inf to 1.22775, saving model to best_model.weights.h5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 28s/step - accuracy: 0.9426 - loss: 0.5836 - val_accuracy: 0.8781 - val_loss: 1.2278\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.9343 - loss: 0.6558 \n",
      "Epoch 2: val_loss improved from 1.22775 to 1.22103, saving model to best_model.weights.h5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27s/step - accuracy: 0.9349 - loss: 0.6504 - val_accuracy: 0.8781 - val_loss: 1.2210\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.9331 - loss: 0.6671 \n",
      "Epoch 3: val_loss improved from 1.22103 to 1.21656, saving model to best_model.weights.h5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 27s/step - accuracy: 0.9340 - loss: 0.6587 - val_accuracy: 0.8781 - val_loss: 1.2166\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.9411 - loss: 0.5920 \n",
      "Epoch 4: val_loss did not improve from 1.21656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 29s/step - accuracy: 0.9400 - loss: 0.6024 - val_accuracy: 0.8781 - val_loss: 1.2219\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.9330 - loss: 0.6668 \n",
      "Epoch 5: val_loss did not improve from 1.21656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 30s/step - accuracy: 0.9339 - loss: 0.6584 - val_accuracy: 0.8781 - val_loss: 1.2220\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.9301 - loss: 0.6983 \n",
      "Epoch 6: val_loss did not improve from 1.21656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 31s/step - accuracy: 0.9318 - loss: 0.6820 - val_accuracy: 0.8781 - val_loss: 1.2209\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.9300 - loss: 0.6936 \n",
      "Epoch 7: val_loss did not improve from 1.21656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 30s/step - accuracy: 0.9317 - loss: 0.6786 - val_accuracy: 0.8781 - val_loss: 1.2202\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.9430 - loss: 0.5724 \n",
      "Epoch 8: val_loss did not improve from 1.21656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 31s/step - accuracy: 0.9414 - loss: 0.5876 - val_accuracy: 0.8781 - val_loss: 1.2238\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27s/step - accuracy: 0.9348 - loss: 0.6499 \n",
      "Epoch 9: val_loss improved from 1.21656 to 1.21487, saving model to best_model.weights.h5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 32s/step - accuracy: 0.9353 - loss: 0.6456 - val_accuracy: 0.8781 - val_loss: 1.2149\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.9383 - loss: 0.6195 \n",
      "Epoch 10: val_loss improved from 1.21487 to 1.21393, saving model to best_model.weights.h5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 31s/step - accuracy: 0.9379 - loss: 0.6228 - val_accuracy: 0.8781 - val_loss: 1.2139\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# Fit the model with the checkpoint callback, using x_train and y_train\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7160392f-8d59-43e1-9eae-4b424cf23141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='best_model.weights.h5' target='_blank'>best_model.weights.h5</a><br>"
      ],
      "text/plain": [
       "/Users/aneebaaslam/Desktop/best_model.weights.h5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(FileLink('best_model.weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c77ebc-5d9d-4705-ae5a-dad2d2402a3e",
   "metadata": {},
   "source": [
    "## **Visualizing Training and Validation losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af4ba77b-4876-4294-801b-68108b5c187b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='training_validation_loss.png' target='_blank'>training_validation_loss.png</a><br>"
      ],
      "text/plain": [
       "/Users/aneebaaslam/Desktop/training_validation_loss.png"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved and ready for download as 'training_validation_loss.png'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_and_download_training_history(history, filename='training_history.png'):\n",
    "    # Plotting the training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Saving the plot as an image\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    display(FileLink(filename))\n",
    "    print(f\"Plot saved and ready for download as '{filename}'\")\n",
    "\n",
    "# Calling the function\n",
    "plot_and_download_training_history(history, filename='training_validation_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0917f8-504f-4c5b-9f26-7b15089e4435",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d96173-77bb-472d-95c2-65effb07d9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
