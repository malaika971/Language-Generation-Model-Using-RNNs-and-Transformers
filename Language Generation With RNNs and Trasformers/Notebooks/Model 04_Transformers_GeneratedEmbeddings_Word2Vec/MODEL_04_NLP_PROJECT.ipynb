{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "-ZIs4mczpmFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MODEL 04**\n",
        "\n",
        "- Transformer architecture with word embeddings trained in assignment\n",
        "2 and using merged dataset of all the group members."
      ],
      "metadata": {
        "id": "Q8Ru3ck58Ian"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "Kk4OJICp8PLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "!pip install nltk rouge-score\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70EuiG2X8O3t",
        "outputId": "8cf057ee-f79e-4854-d189-8830ad39c8af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=045f3469ce3ab8fd1cc78045e462f3c3a40db50dbb48c374a6f16ac207228118\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **LOADING CORPUS (COMBINE TEXTUAL DATA OF ALL GROUP MEMBERS)**"
      ],
      "metadata": {
        "id": "sTbNkCkx8aWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading corpus\n",
        "with open('/content/cleaned_dataset.txt', 'r') as file:\n",
        "    corpus = file.readlines()\n"
      ],
      "metadata": {
        "id": "Hp_ljQRV8kqH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **TOKENIZATION AND LOWER-CASING**"
      ],
      "metadata": {
        "id": "RaYi99Uh8m1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing sentences\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
        "\n",
        "# Lower casing\n",
        "tokenized_corpus = [[word.lower() for word in sentence] for sentence in tokenized_corpus]"
      ],
      "metadata": {
        "id": "I0LZmTOM8tS9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **TRAINING WORD2VEC MODEL FOR GENERATING EMBEDDINGS- SAME AS USED IN ASSIGNMENT 02**"
      ],
      "metadata": {
        "id": "ewKgP1yZ8wbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Word2Vec for generating embedding\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=75, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Saving embeddings with words\n",
        "with open('word2vec_embeddings.txt', 'w') as f:\n",
        "    for word in model.wv.index_to_key:\n",
        "        embedding = model.wv[word]\n",
        "        embedding_str = ' '.join(map(str, embedding))\n",
        "        f.write(f\"{word} {embedding_str}\\n\")"
      ],
      "metadata": {
        "id": "-u_aY7fg87-a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **VERIFYING THE MATCHING OF VOCABULARY SIZE AND EMBEDDING**"
      ],
      "metadata": {
        "id": "do3q6R3u9IE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the size of the vocabulary and the embeddings\n",
        "vocabulary_size = len(model.wv.index_to_key)  # Number of unique words in the vocabulary\n",
        "embedding_size = len(model.wv)  # Number of embeddings generated by the model\n",
        "\n",
        "print(f\"Vocabulary Size: {vocabulary_size}\")\n",
        "print(f\"Embedding Size: {embedding_size}\")\n",
        "\n",
        "# Verifying if they match\n",
        "if vocabulary_size == embedding_size:\n",
        "    print(\"The number of embeddings matches the vocabulary size.\")\n",
        "else:\n",
        "    print(\"Mismatch: Number of embeddings does not match the vocabulary size.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaD_wGxY9Gav",
        "outputId": "a60c2f31-e64f-49cd-9427-9b62301b3ecd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2353\n",
            "Embedding Size: 2353\n",
            "The number of embeddings matches the vocabulary size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **LOADING THE EMBEDDING FILE**"
      ],
      "metadata": {
        "id": "NUwwMgV39lJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading embeddings\n",
        "\n",
        "def load_word2vec_embeddings(embedding_file):\n",
        "    embeddings_index = {}\n",
        "    with open(embedding_file, 'r') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = vector\n",
        "    return embeddings_index\n",
        "\n",
        "embedding_file = '/content/word2vec_embeddings.txt'\n",
        "embeddings_index = load_word2vec_embeddings(embedding_file)\n"
      ],
      "metadata": {
        "id": "nS4Q3bdj9gJg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **INITIALIZING THE TOKENIZER**\n",
        "- For converting the text data into numerical tokens that can be processed by model."
      ],
      "metadata": {
        "id": "MfB6eBlC90H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer and sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)  # Creating sequences\n",
        "sequences = tokenizer.texts_to_sequences(corpus)"
      ],
      "metadata": {
        "id": "20-T2dHr95D6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "### **CREATING SEQUENCES**\n",
        "\n",
        "- Converting each document/sentence into a sequence of integers based on the word_index\n",
        "-  Ensuring that all sequences have the same length for uniform input size\n",
        "- max_sequence_length: Computes the length of the longest sequence in sequences. This determines the length to which all sequences will be padded.\n",
        "- pad_sequences: Adds padding to shorter sequences so they match the max_sequence_length."
      ],
      "metadata": {
        "id": "pP7gwLj0-BV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences\n",
        "max_sequence_length = max(len(seq) for seq in sequences)  # Longest sentence\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for padding token"
      ],
      "metadata": {
        "id": "qIjsAU5L-Fn_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **INITIALIZING EMBEDDING MATRIX**\n",
        "\n",
        "- Embedding Matrix will maps words in our vocabulary to their embeddings. These embeddings will be used as input to our model later on."
      ],
      "metadata": {
        "id": "mr_uyipK-J41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the embedding matrix\n",
        "embedding_dim = 75  # From Word2Vec\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Filling the embedding matrix\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[idx] = embeddings_index[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(size=(embedding_dim,))  # Random vector for missing words\n"
      ],
      "metadata": {
        "id": "KhWYkgKU-VL9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **SPLITTING THE CORPUS (PADDED SEQUENCES) INTO TRAINING AND TESTING DATA**"
      ],
      "metadata": {
        "id": "8pCpmWPQ-W1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_sequences[:, :-1]\n",
        "y = padded_sequences[:, 1:]\n",
        "\n",
        "# Splitting the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "B_coUDFDopAo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **BUILDING TRANSFOMER ARCHITECTURE**"
      ],
      "metadata": {
        "id": "IkoR8zgW-t8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate schedule\n",
        "initial_learning_rate = 0.005\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate,    # Starting learning rate\n",
        "    decay_steps=20000,        # Steps after which decay is applied\n",
        "    decay_rate=0.85,          # Rate at which learning rate is decayed\n",
        "    staircase=True            # If True, the learning rate decays in a staircase manner\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Transformer model parameters\n",
        "d_model = 75                 # Dimension of the embedding vectors\n",
        "num_heads = 8                # Number of attention heads in the multi-head attention mechanism\n",
        "dff = 128                    # Number of neurons in the feedforward network\n",
        "dropout_rate = 0.1           # Dropout rate to prevent overfitting\n",
        "num_layers = 4               # Number of Transformer encoder layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Input layer for the sequences\n",
        "input_seq = Input(shape=(max_sequence_length - 1,))\n",
        "\n",
        "\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,     # Vocabulary size\n",
        "    output_dim=d_model,       # Dimension of each embedding vector\n",
        "    weights=[embedding_matrix],  # Pretrained embedding matrix\n",
        "    trainable=False           # Freezes the embeddings\n",
        ")(input_seq)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Encoder layers\n",
        "x = embedding_layer\n",
        "for i in range(num_layers):\n",
        "    attn_output = MultiHeadAttention(\n",
        "        num_heads=num_heads,  # Number of attention heads\n",
        "        key_dim=d_model       # Dimension of the key vectors\n",
        "    )(x, x)\n",
        "\n",
        "    attn_output = Dropout(dropout_rate)(attn_output)\n",
        "    attn_output = LayerNormalization()(x + attn_output)\n",
        "\n",
        "    ffn_output = Dense(dff, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(d_model)(ffn_output)\n",
        "\n",
        "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "    x = LayerNormalization()(attn_output + ffn_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Output layer\n",
        "output = Dense(vocab_size, activation='softmax')(x)\n",
        "model = Model(inputs=input_seq, outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KZtoBHhY-oyd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "vTiUISlu_AQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilng model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6BlsXvGw_CGs",
        "outputId": "0868f0a7-fdb8-4bcd-e4f3-11642dcddd34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │        \u001b[38;5;34m167,700\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │        \u001b[38;5;34m181,875\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m9,728\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │          \u001b[38;5;34m9,675\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │        \u001b[38;5;34m181,875\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m9,728\u001b[0m │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │          \u001b[38;5;34m9,675\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │        \u001b[38;5;34m181,875\u001b[0m │ layer_normalization_3… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m9,728\u001b[0m │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │          \u001b[38;5;34m9,675\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │        \u001b[38;5;34m181,875\u001b[0m │ layer_normalization_5… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m9,728\u001b[0m │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │          \u001b[38;5;34m9,675\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │            \u001b[38;5;34m150\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1362\u001b[0m, \u001b[38;5;34m2236\u001b[0m)     │        \u001b[38;5;34m169,936\u001b[0m │ layer_normalization_7… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">167,700</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">181,875</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,675</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">181,875</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,675</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">181,875</span> │ layer_normalization_3… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,675</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">181,875</span> │ layer_normalization_5… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,675</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1362</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2236</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">169,936</span> │ layer_normalization_7… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,143,948\u001b[0m (4.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,143,948</span> (4.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m976,248\u001b[0m (3.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">976,248</span> (3.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m167,700\u001b[0m (655.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,700</span> (655.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iFxHlF5_Ylj",
        "outputId": "18ddec06-2d6b-4ca2-ac97-3907704402ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 16s/step - accuracy: 0.7589 - loss: 6.8717 - val_accuracy: 0.9082 - val_loss: 4.4745\n",
            "Epoch 2/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9276 - loss: 4.1965 - val_accuracy: 0.9082 - val_loss: 2.7415\n",
            "Epoch 3/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9355 - loss: 2.4447 - val_accuracy: 0.9082 - val_loss: 1.3256\n",
            "Epoch 4/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9352 - loss: 1.1022 - val_accuracy: 0.9082 - val_loss: 0.9309\n",
            "Epoch 5/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9320 - loss: 0.7210 - val_accuracy: 0.9082 - val_loss: 0.9854\n",
            "Epoch 6/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9267 - loss: 0.7784 - val_accuracy: 0.9082 - val_loss: 1.0592\n",
            "Epoch 7/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9249 - loss: 0.8445 - val_accuracy: 0.9082 - val_loss: 1.0890\n",
            "Epoch 8/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9300 - loss: 0.7989 - val_accuracy: 0.9082 - val_loss: 1.0610\n",
            "Epoch 9/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9221 - loss: 0.8557 - val_accuracy: 0.9082 - val_loss: 0.9790\n",
            "Epoch 10/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9323 - loss: 0.7050 - val_accuracy: 0.9082 - val_loss: 0.9407\n",
            "Epoch 11/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9372 - loss: 0.6737 - val_accuracy: 0.9082 - val_loss: 0.9344\n",
            "Epoch 12/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9264 - loss: 0.7359 - val_accuracy: 0.9082 - val_loss: 0.9483\n",
            "Epoch 13/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9247 - loss: 0.7514 - val_accuracy: 0.9082 - val_loss: 0.9492\n",
            "Epoch 14/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9196 - loss: 0.8004 - val_accuracy: 0.9082 - val_loss: 0.9362\n",
            "Epoch 15/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9359 - loss: 0.6486 - val_accuracy: 0.9082 - val_loss: 0.9362\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f329c51b490>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **TRANSFORMER DECODER**"
      ],
      "metadata": {
        "id": "71uvBvqJBBWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Function to generate predictions for a list of sequences\n",
        "\n",
        "def generate_predictions(model, tokenizer, sequences, max_sequence_length):\n",
        "    predictions = []  # List to store predictions\n",
        "    for seq in sequences:\n",
        "\n",
        "        # Preparing the input sequence, ensuring it's the correct shape for the model\n",
        "        input_seq = seq[:max_sequence_length - 1].reshape(1, -1)  # Taking up to max_sequence_length - 1 tokens and reshaping\n",
        "\n",
        "        pred_probs = model.predict(input_seq, verbose=0)  # Predicting probabilities for the next word\n",
        "\n",
        "        # Mapping predicted indices to words using the tokenizer's index-to-word mapping\n",
        "        pred_words = [tokenizer.index_word.get(idx, '') for idx in pred_probs.argmax(axis=-1)[0]]\n",
        "        predictions.append(pred_words)  # Appending the predicted words to the list\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "lYTkXceT_-2P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Function to generate actual words from sequences\n",
        "\n",
        "def generate_actuals(sequences, tokenizer):\n",
        "    actuals = []  # List to store actual sequences in word form\n",
        "    for seq in sequences:\n",
        "        # Converting sequence indices to words\n",
        "        words = [tokenizer.index_word.get(idx, '') for idx in seq]\n",
        "        actuals.append(words)  # Append the actual words to the list\n",
        "    return actuals"
      ],
      "metadata": {
        "id": "RUtmHmO6AKT8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating  predicted sequences for evaluation\n",
        "predicted_sequences = generate_predictions(model, tokenizer, x_val, max_sequence_length)\n",
        "\n",
        "\n",
        "# Generating actual sequences from the ground truth\n",
        "actual_sequences = generate_actuals(y_val, tokenizer)\n"
      ],
      "metadata": {
        "id": "bUQSStI-AQFl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **MODEL EVALUATION ON BLEU AND ROUGHE**"
      ],
      "metadata": {
        "id": "18zT6ZxgBHtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing BLEU scores for the predicted and actual sequences\n",
        "smooth_fn = SmoothingFunction().method1  # Smoothing function for BLEU scores\n",
        "\n",
        "# Computing BLEU score for each sentence pair\n",
        "bleu_scores = [sentence_bleu([actual], pred, smoothing_function=smooth_fn)\n",
        "               for actual, pred in zip(actual_sequences, predicted_sequences)]\n",
        "# Compute corpus-level BLEU scores with different n-gram weights\n",
        "bleu_1 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(1.0, 0, 0, 0))\n",
        "bleu_2 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.5, 0.5, 0, 0))\n",
        "bleu_3 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.33, 0.33, 0.33, 0))\n",
        "bleu_4 = corpus_bleu([[a] for a in actual_sequences], predicted_sequences, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "# Printing BLEU scores\n",
        "print(\"BLEU Scores:\")\n",
        "print(f\"BLEU-1: {bleu_1:.4f}\")\n",
        "print(f\"BLEU-2: {bleu_2:.4f}\")\n",
        "print(f\"BLEU-3: {bleu_3:.4f}\")\n",
        "print(f\"BLEU-4: {bleu_4:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Computing ROUGE scores using a scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "# Initialize cumulative ROUGE scores with offsets for clarity\n",
        "rouge_1, rouge_2, rouge_l = 0, 0, 0\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over actual and predicted sequences\n",
        "for actual, pred in zip(actual_sequences, predicted_sequences):\n",
        "    # Converting sequences to strings for scoring\n",
        "    actual_str = ' '.join(actual)\n",
        "    pred_str = ' '.join(pred)\n",
        "    # Computing ROUGE scores for the pair\n",
        "    scores = scorer.score(actual_str, pred_str)\n",
        "    rouge_1 += scores['rouge1'].fmeasure  # Accumulate ROUGE-1 F1 scores\n",
        "    rouge_2 += scores['rouge2'].fmeasure  # Accumulate ROUGE-2 F1 scores\n",
        "    rouge_l += scores['rougeL'].fmeasure  # Accumulate ROUGE-L F1 scores\n",
        "\n",
        "\n",
        "\n",
        "# Averaging ROUGE scores over all sequences\n",
        "n = len(actual_sequences)\n",
        "print(\"\\n ROUGE Scores:\")\n",
        "print(f\"ROUGE-1 (F1): {rouge_1 / n:.4f}\")\n",
        "print(f\"ROUGE-2 (F1): {rouge_2 / n:.4f}\")\n",
        "print(f\"ROUGE-L (F1): {rouge_l / n:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89dkIbSrxhQ6",
        "outputId": "b8c4387d-1ea5-42ef-fb15-8b40788cc00e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Scores:\n",
            "BLEU-1: 0.9082\n",
            "BLEU-2: 0.9082\n",
            "BLEU-3: 0.9090\n",
            "BLEU-4: 0.9081\n",
            "\n",
            " ROUGE Scores:\n",
            "ROUGE-1 (F1): 0.4250\n",
            "ROUGE-2 (F1): 0.4550\n",
            "ROUGE-L (F1): 0.5250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "_8SAk3dBqRfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **4×  MODEL 4 CHECK POINTS**"
      ],
      "metadata": {
        "id": "f1KjjzrQDNli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checkpoint 1: After Training Word2Vec Model**"
      ],
      "metadata": {
        "id": "5KzlVaWdDscY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint 1: After Training Word2Vec Model\n",
        "\n",
        "# SavING Keras Transformer model checkpoint\n",
        "model.save('word2vec_model_checkpoint.keras')"
      ],
      "metadata": {
        "id": "m6xOjOyfzCoB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('word2vec_model_checkpoint.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kG-vFanrFSMh",
        "outputId": "c9071871-5e8e-4ec1-d880-7df2a5f39fbc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cc913ce3-d889-4a92-9712-ce39c0aa25a9\", \"word2vec_model_checkpoint.keras\", 12598176)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checkpoint 2: After Initializing the Embedding Matrix**"
      ],
      "metadata": {
        "id": "JCKmlgvWD6Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embedding matrix checkpoint\n",
        "np.save('embedding_matrix_checkpoint.npy', embedding_matrix)\n"
      ],
      "metadata": {
        "id": "50of6mKnDhqS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checkpoint 3: After Each Training Epoch**\n"
      ],
      "metadata": {
        "id": "GmY8vaCmEKku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a checkpoint callback\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='model_checkpoint_epoch_{epoch:02d}.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False\n",
        ")\n",
        "\n",
        "# Adding the callback in model training\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=15, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGpgaY0-EFvT",
        "outputId": "c996641d-8dea-4d2d-c922-83a3e2f5b4b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9274 - loss: 0.7229 - val_accuracy: 0.9082 - val_loss: 0.9315\n",
            "Epoch 2/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9345 - loss: 0.6579 - val_accuracy: 0.9082 - val_loss: 0.9356\n",
            "Epoch 3/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9234 - loss: 0.7562 - val_accuracy: 0.9082 - val_loss: 0.9339\n",
            "Epoch 4/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9371 - loss: 0.6337 - val_accuracy: 0.9082 - val_loss: 0.9360\n",
            "Epoch 5/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9315 - loss: 0.6813 - val_accuracy: 0.9082 - val_loss: 0.9290\n",
            "Epoch 6/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9250 - loss: 0.7401 - val_accuracy: 0.9082 - val_loss: 0.9296\n",
            "Epoch 7/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9292 - loss: 0.7026 - val_accuracy: 0.9082 - val_loss: 0.9441\n",
            "Epoch 8/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9227 - loss: 0.7604 - val_accuracy: 0.9082 - val_loss: 0.9509\n",
            "Epoch 9/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9264 - loss: 0.7311 - val_accuracy: 0.9082 - val_loss: 0.9445\n",
            "Epoch 10/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9260 - loss: 0.7278 - val_accuracy: 0.9082 - val_loss: 0.9340\n",
            "Epoch 11/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9291 - loss: 0.6996 - val_accuracy: 0.9082 - val_loss: 0.9356\n",
            "Epoch 12/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9271 - loss: 0.7186 - val_accuracy: 0.9082 - val_loss: 0.9400\n",
            "Epoch 13/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9272 - loss: 0.7204 - val_accuracy: 0.9082 - val_loss: 0.9429\n",
            "Epoch 14/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9187 - loss: 0.7945 - val_accuracy: 0.9082 - val_loss: 0.9452\n",
            "Epoch 15/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9280 - loss: 0.7116 - val_accuracy: 0.9082 - val_loss: 0.9498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f31eb20fa60>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "epoch = 15\n",
        "filename = f'model_checkpoint_epoch_{epoch:02d}.weights.h5'\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    files.download(filename)\n",
        "else:\n",
        "    print(f\"Error: File '{filename}' not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7xdqvpLgGGrw",
        "outputId": "60719ced-ee69-4748-a1f0-9ee3488f0acb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5a3b8c8-bdae-4859-9762-a91a3ce94cc4\", \"model_checkpoint_epoch_15.weights.h5\", 12570732)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### **Checkpoint 4: Best Performing Model**"
      ],
      "metadata": {
        "id": "wv-tDBIGGDUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='best_model.weights.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    save_weights_only=True\n",
        ")\n",
        "\n",
        "# Fit the model with the checkpoint callback, using x_train and y_train\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM0jwmfjF7v8",
        "outputId": "310f6270-74f0-479f-d73f-f8ad6c00db00"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9314 - loss: 0.6854\n",
            "Epoch 1: val_loss improved from inf to 0.94269, saving model to best_model.weights.h5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9310 - loss: 0.6881 - val_accuracy: 0.9082 - val_loss: 0.9427\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9414 - loss: 0.5950\n",
            "Epoch 2: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9385 - loss: 0.6202 - val_accuracy: 0.9082 - val_loss: 0.9553\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9310 - loss: 0.6834\n",
            "Epoch 3: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9308 - loss: 0.6861 - val_accuracy: 0.9082 - val_loss: 0.9529\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9269 - loss: 0.7177\n",
            "Epoch 4: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9277 - loss: 0.7116 - val_accuracy: 0.9082 - val_loss: 0.9481\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9229 - loss: 0.7543\n",
            "Epoch 5: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9247 - loss: 0.7390 - val_accuracy: 0.9082 - val_loss: 0.9464\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9285 - loss: 0.7102\n",
            "Epoch 6: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9289 - loss: 0.7062 - val_accuracy: 0.9082 - val_loss: 0.9507\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9304 - loss: 0.6919\n",
            "Epoch 7: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9303 - loss: 0.6921 - val_accuracy: 0.9082 - val_loss: 0.9489\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9188 - loss: 0.7927\n",
            "Epoch 8: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9216 - loss: 0.7681 - val_accuracy: 0.9082 - val_loss: 0.9482\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9423 - loss: 0.5865\n",
            "Epoch 9: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9393 - loss: 0.6137 - val_accuracy: 0.9082 - val_loss: 0.9548\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9221 - loss: 0.7612\n",
            "Epoch 10: val_loss did not improve from 0.94269\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9241 - loss: 0.7445 - val_accuracy: 0.9082 - val_loss: 0.9458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading\n",
        "\n",
        "files.download('best_model.weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Eeg0UURDG9Kz",
        "outputId": "d1d0b2d1-79bc-426e-bf99-4d073554c690"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2d0064a0-df34-4459-8565-34b036cbc01c\", \"best_model.weights.h5\", 12570732)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "wUH0s7nfHya0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualizing Training and Validation losses**"
      ],
      "metadata": {
        "id": "33Bpx-FJKj2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_and_download_training_history(history, filename='training_history.png'):\n",
        "    # Plotting the training and validation loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Saving the plot as an image\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    files.download(filename)\n",
        "    print(f\"Plot saved and ready for download as '{filename}'\")\n",
        "\n",
        "# Calling the function\n",
        "plot_and_download_training_history(history, filename='training_validation_loss.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "kArASF7XHzYs",
        "outputId": "1a1ec396-13b6-4f65-a5d9-23411b1e02f1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a82e5ba6-ba52-4877-bc54-ec4baf858f11\", \"training_validation_loss.png\", 95588)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plot saved and ready for download as 'training_validation_loss.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "A6XWOYnATGmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 4: DONE BY MALAIKA AHMED (492471)\n",
        "### DEC 31, 2024"
      ],
      "metadata": {
        "id": "J3t3GsZMHNeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dfXZrlZhHir7"
      }
    }
  ]
}